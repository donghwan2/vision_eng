# English Problem Solver v2
# ê¸°ëŠ¥1. ê·¸ë˜í”„ ì´ë¯¸ì§€ ì—…ë¡œë“œí•˜ë©´ gpt-4-visionì´ ë‹µë³€
# - ê·¸ë˜í”„ ì´ë¯¸ì§€ ì—…ë¡œë“œ
# - ì§€ë¬¸ í…ìŠ¤íŠ¸ ì—…ë¡œë“œ

# ê¸°ëŠ¥2. í…ìŠ¤íŠ¸ ì…ë ¥í•˜ë©´ gpt-4-turboê°€ ë‹µë³€


from openai import OpenAI
from IPython.display import Image
from dotenv import load_dotenv
load_dotenv()
client = OpenAI()
# llm : langchain.ChatOpenAI
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage

import os
import base64
import requests

api_key = os.environ.get('OPENAI_API_KEY')


import streamlit as st
import pandas as pd
import numpy as np
import time
from datetime import datetime

from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration
from PIL import Image as Img
from IPython.display import Image

# https://velog.io/@wonjun12/Streamlit-%ED%8C%8C%EC%9D%BC-%EC%97%85%EB%A1%9C%EB%93%9C


st.header("ğŸ“„English Problem SolverğŸ“Š")

# ì‚¬ì´ë“œì— listì˜ ì„ íƒë°•ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.
select = st.sidebar.selectbox('ë©”ë‰´', ['í…ìŠ¤íŠ¸ ë¶„ì„', 'ê·¸ë˜í”„ ì´ë¯¸ì§€ ë¶„ì„'])

if select == 'í…ìŠ¤íŠ¸ ë¶„ì„':

    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    question = st.text_area("ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", height=10)

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ìƒì„±
    messages=[{"role": "system", "content": """
               You are a helpful assistant. 
               Answer the questions given and explain your reasoning.
               You must answer in Korean."""}]

    question_dict = {
                "role": "user",
                "content": question ,  # ì²« ë²ˆì§¸ ì§ˆë¬¸
            }

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
    messages.append(question_dict)

    # ë²„íŠ¼ ëˆ„ë¥´ë©´ ë‹µë³€ ë°›ê¸° ì‹œì‘
    if st.button('í’€ì–´ì¤˜!'):
    # st.write('Why hello there')

        # ë‹µë³€ ë°›ê¸°
        completion = client.chat.completions.create(
            model="gpt-4-0125-preview",          # "gpt-3.5-turbo-0125", "gpt-4-0125-preview"
            messages = messages,
        )

        response = completion.choices[0].message.content

        st.info(response)


if select == 'ê·¸ë˜í”„ ì´ë¯¸ì§€ ë¶„ì„':
    # íŒŒì¼ ì—…ë¡œë“œ (ì—…ë¡œë“œ ê¸°ëŠ¥)
    img_file = st.file_uploader("", type=['png', 'jpg', 'jpeg'])

    # context(ì§€ë¬¸) ì…ë ¥ë°›ê¸°
    context = st.text_input("ğŸ“„ì˜ì–´ ì§€ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", "")

    if (img_file is not None) and (len(context) != 0):    # ë§Œì•½ ê·¸ë˜í”„ ì´ë¯¸ì§€ íŒŒì¼ê³¼ ì§€ë¬¸ í…ìŠ¤íŠ¸ê°€ ì—…ë¡œë“œë˜ë©´,
        st.image(img_file, width=500)
        # image = Image.open(img_file)
        # print("image: ", image)
        st.text("Q. ë‹¤ìŒ ì¤‘ ìœ„ ë„í‘œì˜ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²ƒì€?")
        st.text_area("", context)

        # ë²„íŠ¼ ëˆ„ë¥´ë©´ ë‹µë³€ ë°›ê¸° ì‹œì‘
        if st.button('í’€ì–´ì¤˜!'):
            # --------------------------deplotìœ¼ë¡œ ìˆ˜ì¹˜ ì¶”ì¶œí•˜ê¸°-------------------------

            processor = Pix2StructProcessor.from_pretrained('nuua/ko-deplot')
            model = Pix2StructForConditionalGeneration.from_pretrained('nuua/ko-deplot')

            # ê·¸ë˜í”„ ì´ë¯¸ì§€ì—ì„œ ìˆ˜ì¹˜ ì¶”ì¶œ
            image = Img.open(img_file)

            inputs = processor(images=image, text="Generate underlying data table of the figure below:", return_tensors="pt")
            predictions = model.generate(**inputs, max_new_tokens=512)
            result = processor.decode(predictions[0], skip_special_tokens=True)

            st.text_area(result)

            # --------------------------gpt-4-visionìœ¼ë¡œ ë¬¸ì œ í’€ê¸°--------------------------

            # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ìƒì„±
            messages=[{"role": "system", "content": """
                       You must answer in You are a math assistant who does accurate calculations. 
                       Correct the algebra of the given numbers and choose the one you think is the most incorrect.
                       """}]


            # ì…ë ¥ ì˜ˆì‹œ(image_path, prompt)
            image_path = img_file.name

            # ì²«ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±
            question = f""" 
            ê·¸ë˜í”„ ë¶„ì„ resultë¥¼ ì œê³µí•´ì¤„ê²Œ.
            result : {result}.

            Q. ë‹¤ìŒ ì¤‘ ê·¸ë˜í”„ ë‚´ìš©ê³¼ ê°€ì¥ í‹€ë¦° ë¬¸ì¥ì´ ëª‡ ë²ˆì¸ì§€ ì°¾ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´. 
            {context}
            """ 

            # Function to encode the image
            def encode_image(image_path):
                with open(image_path, "rb") as image_file:
                    return base64.b64encode(image_file.read()).decode('utf-8')
                    
            # Getting the base64 string
            base64_image = encode_image(image_path)

            question_dict = {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": question},
                        {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                        },
                        },
                    ],
                    }

            # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
            messages.append(question_dict)

            # ë‹µë³€ ë°›ê¸°
            completion = client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages = messages,
            )

            response = completion.choices[0].message.content

            st.info(response)

    else:
        st.info('â˜ï¸ ê·¸ë˜í”„ ì´ë¯¸ì§€ì™€ ì§€ë¬¸ì„ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì œë¥¼ í’€ì–´ë“œë¦½ë‹ˆë‹¤.')


